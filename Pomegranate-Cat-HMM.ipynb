{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <img src=\"https://github.com/jmschrei/pomegranate/blob/master/docs/logo/pomegranate-logo.png?raw=true\" style=\"width: 200px;\" align=left /> :  A demo, featuring Chewbacca the YouTube Cat\n",
    "\n",
    "\n",
    "This presentation was derived from a mixture of source materials:\n",
    " - [Pomegranate Tutorials](https://github.com/jmschrei/pomegranate/tree/master/tutorials)\n",
    " - [Introduction to Hidden Markov Models with Python Networkx and Sklearn](http://www.blackarbs.com/blog/introduction-hidden-markov-models-python-networkx-sklearn/2/9/2017)\n",
    "\n",
    "**Find this demo on github**:  [mooneyj3: cs571_hmm_demos](https://github.com/mooneyj3/cs571_hmm_demos)\n",
    "***\n",
    "\n",
    "### Course: CS 571, Machine Learning, Western Washington University (Brian Hutchinson)\n",
    "**Assignment:  Advanced Lecture Topics, Hidden Markov Models**\n",
    "\n",
    "**Author**: Jonny Mooneyham with Alex Emanuelson and Simon Haile\n",
    "***\n",
    "\n",
    "# Getting Started\n",
    "Pomegranate is the main package we will use. Pomegranates flagship product is the Hidden Markov Model Package (HMM).  The source code and excellent documentation can be found on [Pomegranate's GitHub Page](https://github.com/jmschrei/pomegranate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomegranate import *\n",
    "import numpy as np\n",
    "import pandas as pd # used to display data nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Chewbacca, or *Chewy*, is a cat.  He has four activities that we observe: *sleeping, eating, destroying furniture, and making YouTube videos*.\n",
    "\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy.jpg?raw=true\" width=\"250px\" align=\"left\">\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy_sleep.jpg?raw=true\" width=\"250px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The initial probability of any of these states is given below based on what we know about cats and Chewy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation</th>\n",
       "      <th>Initial_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sleep</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eat</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>destroy_furniture</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make_videos</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Observation  Initial_Prob\n",
       "0              sleep          0.60\n",
       "1                eat          0.05\n",
       "2  destroy_furniture          0.10\n",
       "3        make_videos          0.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of States and their probabilities\n",
    "states = ['sleep', # cats sleep for 60% of their lives\n",
    "          'eat',   # cats are crepuscular, active during twilight\n",
    "          'destroy_furniture',  # cats contribute to 10.2% of annual revenues in the furniture industry\n",
    "          'make_videos'] # there are more than 2 million cat videos on YouTube\n",
    "pi = [0.6, 0.05, 0.1, 0.25]\n",
    "\n",
    "# create state space and initial state probabilities\n",
    "state_space = pd.Series(pi, index=states, name='states')\n",
    "\n",
    "# Pandas DataFrame to display values\n",
    "(pd.DataFrame()\n",
    "    .assign(Observation=states)\n",
    "    .assign(Initial_Prob=pi)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Probabilities\n",
    "Next, we will define the **transition probabilities**.\n",
    "These are the probabilities of staying in the same state or moving to a different state.\n",
    "This is an (M x M) matrix where M is the number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  sleep   eat destroy_furniture make_videos\n",
      "sleep               0.4   0.2              0.05        0.35\n",
      "eat                 0.8  0.05               0.1        0.05\n",
      "destroy_furniture   0.6  0.05               0.1        0.25\n",
      "make_videos         0.1   0.4               0.1         0.4\n",
      "\n",
      "Probability Totals\n",
      "sleep                1.0\n",
      "eat                  1.0\n",
      "destroy_furniture    1.0\n",
      "make_videos          1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "q_df = pd.DataFrame(columns=states, index=states)\n",
    "\n",
    "# These are the states according to their transitions\n",
    "# {state} -> [sleeping, eating, dest_furn, make_vids]\n",
    "q_df.loc[states[0]] = [0.4, 0.2, 0.05, 0.35] # sleep \n",
    "q_df.loc[states[1]] = [0.8, 0.05, 0.1, 0.05] # eating\n",
    "q_df.loc[states[2]] = [0.6, 0.05, 0.1, 0.25] # dest_furn\n",
    "q_df.loc[states[3]] = [0.1, 0.4, 0.1, 0.4] #make_vids\n",
    "\n",
    "print(q_df)\n",
    "\n",
    "q = q_df.values\n",
    "# print('\\n', q, q.shape, '\\n')\n",
    "\n",
    "print(\"\\nProbability Totals\")\n",
    "print(q_df.sum(axis=1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chewy's Markov Chain\n",
    "What we have now is a Markov Chain for Chewbacca's activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/pet_cat.png?raw=true\" width=\"350px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains in Pomegranate\n",
    "Fortunately, the setup for this is fairly straightforward, but a little more arduous than my example above.\n",
    "\n",
    "From the Pomegranate library, we will create a **discrete distrubtion**, and a **conditional probability** table.\n",
    "\n",
    "Last, we will **initialize a Markov Chain** with the discrete distribution and conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Discrete Distribution\n",
    "d1 = DiscreteDistribution({'sleep': 0.6, \n",
    "                           'eat': 0.05,\n",
    "                           'destroy_furniture': 0.1, \n",
    "                           'make_videos': 0.25})\n",
    "\n",
    "# Setting up the Conditional Probability Table\n",
    "d2 = ConditionalProbabilityTable([['sleep', 'sleep', 0.4],\n",
    "                                  ['sleep', 'eat', 0.2],\n",
    "                                  ['sleep', 'destroy_furniture', 0.05],\n",
    "                                  ['sleep', 'make_videos', 0.35],\n",
    "                                  ['eat', 'sleep', 0.8],\n",
    "                                  ['eat', 'eat', 0.05],\n",
    "                                  ['eat', 'destroy_furniture', 0.1],\n",
    "                                  ['eat', 'make_videos', 0.05], \n",
    "                                  ['destroy_furniture', 'sleep', 0.6],\n",
    "                                  ['destroy_furniture', 'eat', 0.05],\n",
    "                                  ['destroy_furniture', 'destroy_furniture', 0.1],\n",
    "                                  ['destroy_furniture', 'make_videos', 0.25],\n",
    "                                  ['destroy_furniture', 'sleep', 0.1],\n",
    "                                  ['destroy_furniture', 'eat', 0.4],\n",
    "                                  ['destroy_furniture', 'destroy_furniture', 0.1], \n",
    "                                  ['destroy_furniture', 'make_videos', 0.4]],\n",
    "                                [d1])\n",
    "\n",
    "# Initializing the Markov Chain\n",
    "markov_chain = MarkovChain([d1, d2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Probabilities\n",
    "(*From the Docs*): The Markov Chains library has log probability, fit, summarize, and from summaries methods implemented. They do not have classification capabilities by themselves, but when combined with a Naive Bayes classifier can be used to do discrimination between multiple models (see the Naive Bayes tutorial notebook).\n",
    "\n",
    "Below are examples of the **log_probability** function displaying the likelihood of a sequence of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5108256237659907\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "log_prob = markov_chain.log_probability( [\"sleep\"] )\n",
    "print(log_prob)\n",
    "print(np.exp(log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003200000000000006\n"
     ]
    }
   ],
   "source": [
    "log_prob = markov_chain.log_probability( [\"eat\", \"sleep\", \"eat\", \"destroy_furniture\", \"make_videos\"] )\n",
    "print(np.exp(log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09600000000000002\n"
     ]
    }
   ],
   "source": [
    "log_prob = markov_chain.log_probability( [\"sleep\" , \"sleep\", \"sleep\"])\n",
    "print(np.exp(log_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Markov Chain using Fit\n",
    "We can fit the model to sequences which we pass in, and as expected, get better performance on sequences which we train on.  We can view the resulting probabilities of these specific sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain.fit([[\"eat\", \"sleep\", \"eat\", \"eat\", \"eat\", \"destroy_furniture\", \"make_videos\"],\n",
    "         [\"sleep\"],\n",
    "         [\"sleep\" , \"sleep\", \"sleep\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After fitting (training) the model with new data\n",
    "The Markov model has changed, we can now view the new distributions that the model has learned using by looking at the **distributions**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"class\" :\"Distribution\",\n",
      "    \"name\" :\"DiscreteDistribution\",\n",
      "    \"parameters\" :[\n",
      "        {\n",
      "            \"sleep\" :0.6666666666666666,\n",
      "            \"eat\" :0.3333333333333333,\n",
      "            \"destroy_furniture\" :0.0,\n",
      "            \"make_videos\" :0.0\n",
      "        }\n",
      "    ],\n",
      "    \"frozen\" :false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(markov_chain.distributions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\tsleep\t0.6666666666666666\n",
      "sleep\teat\t0.3333333333333333\n",
      "sleep\tdestroy_furniture\t0.0\n",
      "sleep\tmake_videos\t0.0\n",
      "eat\tsleep\t0.25\n",
      "eat\teat\t0.5\n",
      "eat\tdestroy_furniture\t0.25\n",
      "eat\tmake_videos\t0.0\n",
      "destroy_furniture\tsleep\t0.0\n",
      "destroy_furniture\teat\t0.0\n",
      "destroy_furniture\tdestroy_furniture\t0.0\n",
      "destroy_furniture\tmake_videos\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(markov_chain.distributions[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does one of our original predictions look like in this new model?\n",
    "Compared to `0.000320` from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.969813299576001\n",
      "0.006944444444444444\n"
     ]
    }
   ],
   "source": [
    "log_prob = markov_chain.log_probability( [\"eat\", \"sleep\", \"eat\", \"destroy_furniture\", \"make_videos\"] )\n",
    "print(log_prob)\n",
    "print(np.exp(log_prob))\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model with Pomegranate\n",
    "\n",
    "## More Background on Chewy\n",
    "\n",
    "Evidently, Chewbacca's mood is affected by his viewer base and number of views on YouTube. Since he can only meow, and is bound by his monetization agreement with YouTube, he cannot disclose this information to us, perhaps we can use an HMM to help us guess the state of Chewy's viewership.\n",
    "\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy_TV.jpg?raw=true\" width=\"250px\" align=\"left\">\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy_box.jpg?raw=true\" width=\"250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is, we don't know what his mood is, we can only guess based on viewership.\n",
    "\n",
    "We have two distributions, if his viewers are **increasing**, then Chewbacca's mood is usually good, he sleeps more, eats regularly and destroys less furniture, and keeps a steady pace of videos.  If viewership is **decreasing**, then he eats and sleeps less because he is depressed, destroys more furniture to vent his frustration, and creates more videos to try and get more users.\n",
    " \n",
    "This can be setup with some initial observations or experience, or it can be setup with a random distribution if uncertainty is high.  We begin by creating any number of `DiscreteDistribution`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "increasing = DiscreteDistribution({'sleep': 0.5, \n",
    "                                   'eat': 0.2,\n",
    "                                   'dest': 0.05,                            \n",
    "                                   'vids': 0.25})\n",
    "\n",
    "decreasing = DiscreteDistribution({'sleep': 0.2, \n",
    "                                   'eat': 0.05,\n",
    "                                   'dest': 0.4,                            \n",
    "                                   'vids': 0.35})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create states tied to our distributions using `State`.\n",
    "\n",
    "Then initialize a `HiddenMarkovModel` and `add_states`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = State( increasing, name=\"increasing\" )\n",
    "s2 = State( decreasing, name=\"decreasing\" )\n",
    "\n",
    "hmm = HiddenMarkovModel()\n",
    "hmm.add_states(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we setup the **transitions** by using `add_transition`. Chewbacca is generally in a good mood most of the time and has good viewership.  This is our initial guess of the probability of staying within a state or moving to a new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm.add_transition(hmm.start, s1, 0.8)\n",
    "hmm.add_transition(hmm.start, s2, 0.2)\n",
    "hmm.add_transition(s1, s1, 0.8)\n",
    "hmm.add_transition(s1, s2, 0.2)\n",
    "hmm.add_transition(s2, s1, 0.2)\n",
    "hmm.add_transition(s2, s2, 0.8)\n",
    "hmm.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make some predictions about Chewy's mood based on some observations using `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: decreasing\n",
      "1: increasing\n",
      "\n",
      "sequence: sleep\teat\tsleep\tvids\tsleep\tdest\tsleep\teat\tvids\tvids\n",
      "hmm pred: 1\t1\t1\t1\t1\t0\t1\t1\t1\t0\n",
      "\n",
      "sequence: dest\tvids\tdest\tvids\tdest\tvids\tsleep\tsleep\tsleep\n",
      "hmm pred: 0\t0\t0\t0\t0\t0\t1\t1\t1\n"
     ]
    }
   ],
   "source": [
    "seq1 = ['sleep', 'eat', 'sleep', 'vids', 'sleep', 'dest', 'sleep', 'eat', 'vids', 'vids']\n",
    "seq2 = ['dest', 'vids', 'dest', 'vids', 'dest', 'vids', 'sleep', 'sleep', 'sleep']\n",
    "\n",
    "print(\"0:\", hmm.states[0].name)\n",
    "print(\"1:\", hmm.states[1].name, end=\"\\n\\n\")\n",
    "\n",
    "predictions1 = hmm.predict( seq1 )\n",
    "print(\"sequence: {}\".format( \"\\t\".join( seq1 )))\n",
    "print(\"hmm pred: {}\".format( \"\\t\".join( map( str, predictions1)) ), end=\"\\n\\n\")\n",
    "\n",
    "predictions2 = hmm.predict( seq2 )\n",
    "print(\"sequence: {}\".format( \"\\t\".join( seq2 )))\n",
    "print(\"hmm pred: {}\".format( \"\\t\".join( map( str, predictions2)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `predict_proba` allows us to look at the predictions based off of their probabilities. These are the **emission probability values** calculated by the **forward backward algorithm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0: decreasing\n",
      "state 1: increasing\n",
      "\n",
      "        decreasing  increasing \t\tprediction\n",
      "sleep\t[0.03775431 0.96224569]\t\t1\n",
      "eat\t[0.05113983 0.94886017]\t\t1\n",
      "sleep\t[0.12944284 0.87055716]\t\t1\n",
      "vids\t[0.31235225 0.68764775]\t\t1\n",
      "sleep\t[0.35368476 0.64631524]\t\t1\n",
      "dest\t[0.63454255 0.36545745]\t\t0\n",
      "sleep\t[0.31494002 0.68505998]\t\t1\n",
      "eat\t[0.23641257 0.76358743]\t\t1\n",
      "vids\t[0.43505411 0.56494589]\t\t1\n",
      "vids\t[0.51560427 0.48439573]\t\t0\n"
     ]
    }
   ],
   "source": [
    "probs1 = hmm.predict_proba( seq1 )\n",
    "\n",
    "print(\"state 0:\", hmm.states[0].name)\n",
    "print(\"state 1:\", hmm.states[1].name)\n",
    "print()\n",
    "\n",
    "print (\"       \", hmm.states[0].name, \"\", hmm.states[1].name,\"\\t\\tprediction\")\n",
    "for i in range(len(seq1)):\n",
    "    print(seq1[i], probs1[i], \"\", predictions1[i],sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 0: decreasing\n",
      "state 1: increasing\n",
      "\n",
      "        decreasing  increasing \t\tprediction\n",
      "dest\t[0.03775431 0.96224569]\t\t0\n",
      "vids\t[0.05113983 0.94886017]\t\t0\n",
      "dest\t[0.12944284 0.87055716]\t\t0\n",
      "vids\t[0.31235225 0.68764775]\t\t0\n",
      "dest\t[0.35368476 0.64631524]\t\t0\n",
      "vids\t[0.63454255 0.36545745]\t\t0\n",
      "sleep\t[0.31494002 0.68505998]\t\t1\n",
      "sleep\t[0.23641257 0.76358743]\t\t1\n",
      "sleep\t[0.43505411 0.56494589]\t\t1\n"
     ]
    }
   ],
   "source": [
    "probs2 = hmm.predict_proba( seq1 )\n",
    "\n",
    "print(\"state 0:\", hmm.states[0].name)\n",
    "print(\"state 1:\", hmm.states[1].name)\n",
    "print()\n",
    "\n",
    "print (\"       \", hmm.states[0].name, \"\", hmm.states[1].name,\"\\t\\tprediction\")\n",
    "for i in range(len(seq2)):\n",
    "    print(seq2[i], probs2[i], \"\", predictions2[i],sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the `hmm.forward_backward( seq )`, this returns the **emissions** and the **transition** probability tables.\n",
    "\n",
    "The emissions are the log probabilities, which we have already seen converted into normal probabilities above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.77764161 0.72768163 0.         0.        ]\n",
      " [1.20553159 5.28914517 0.         0.        ]\n",
      " [0.03775431 0.96224569 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "trans, ems = hmm.forward_backward(seq1)\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(from the docs)* This is the transition table, which has the soft count of the number of transitions across an edge in the model given a single sequence. It is a square matrix of size equal to the number of states (including start and end state), with number of transitions from (row_id) to (column_id). These counts are not normalized to the length of the input sequence, but can easily be done so by dividing by row sums, column sums, or entire table sums, depending on your application.\n",
    "\n",
    "A possible reason not to normalize is to run several sequences through and add up their tables, because normalizing in the end and extracting some domain knowledge.\n",
    "\n",
    "---\n",
    "\n",
    "We've been using the forward backward algorithm and maximum a posteriori for decoding thus far, however maximum a posteriori decoding has the side effect that it is possible that it predicts impossible sequences in some edge cases. An alternative is **Viterbi** decoding, which at each step takes the most likely path, instead of sum of all paths, to produce hard assignments.\n",
    "\n",
    "Here we see `predict` being used with `algorithm=viterbi` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm state 0: decreasing\n",
      "hmm state 1: increasing\n",
      "\n",
      "sequence1: sleep\teat\tsleep\tvids\tsleep\tdest\tsleep\teat\tvids\tvids\n",
      "hmm pred1: 1\t1\t1\t1\t1\t1\t1\t1\t1\t1\n",
      "\n",
      "sequence2: dest\tvids\tdest\tvids\tdest\tvids\tsleep\tsleep\tsleep\n",
      "hmm pred: 0\t0\t0\t0\t0\t0\t1\t1\t1\n"
     ]
    }
   ],
   "source": [
    "print(\"hmm state 0: {}\".format( hmm.states[0].name ))\n",
    "print(\"hmm state 1: {}\".format( hmm.states[1].name ))\n",
    "print()\n",
    "\n",
    "hmm_predictions1 = hmm.predict( seq1, algorithm='viterbi' )[1:]\n",
    "print(\"sequence1: {}\".format( '\\t'.join( seq1 ) ))\n",
    "print(\"hmm pred1: {}\".format( '\\t'.join( map( str, hmm_predictions1 ) ) ))\n",
    "\n",
    "print()\n",
    "hmm_predictions2 = hmm.predict( seq2, algorithm='viterbi' )[1:]\n",
    "print(\"sequence2: {}\".format( '\\t'.join( seq2 ) ))\n",
    "print(\"hmm pred: {}\".format( '\\t'.join( map( str, hmm_predictions2 ) ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training HMM's\n",
    "There are two main algorithms for training hidden Markov models-- Baum Welch (structured version of Expectation Maximization), and Viterbi training. **Since we don't start off with labels on the data, these are both unsupervised training algorithms.** In order to assign labels, Baum Welch uses EM to assign soft labels (weights in this case) to each point belonging to each state, and then using weighted MLE estimates to update the distributions. Viterbi assigns hard labels to each observation using the Viterbi algorithm, and then updates the distributions based on these hard labels.\n",
    "\n",
    "We use the *same discreate distributions* as above and create `hmm2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "increasing = DiscreteDistribution({'sleep': 0.5, \n",
    "                                   'eat': 0.2,\n",
    "                                   'dest': 0.05,                            \n",
    "                                   'vids': 0.25})\n",
    "\n",
    "decreasing = DiscreteDistribution({'sleep': 0.2, \n",
    "                                   'eat': 0.05,\n",
    "                                   'dest': 0.4,                            \n",
    "                                   'vids': 0.35})\n",
    "\n",
    "s1 = State( increasing, name=\"increasing\" )\n",
    "s2 = State( decreasing, name=\"decreasing\" )\n",
    "\n",
    "hmm2 = HiddenMarkovModel()\n",
    "hmm2.add_states(s1, s2)\n",
    "\n",
    "hmm2.add_transition(hmm2.start, s1, 0.8)\n",
    "hmm2.add_transition(hmm2.start, s2, 0.2)\n",
    "hmm2.add_transition(s1, s1, 0.8)\n",
    "hmm2.add_transition(s1, s2, 0.2)\n",
    "hmm2.add_transition(s2, s1, 0.2)\n",
    "hmm2.add_transition(s2, s2, 0.8)\n",
    "hmm2.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, now lets feed some data and apply the `baum-welch` algorithm.  \n",
    "\n",
    "The result prints the **training improvement**.  \n",
    "\n",
    "**Inertia** is used to prevent updates from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0516327737924627"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm2.fit( [seq1, seq2,\n",
    "           ['sleep'], \n",
    "          ['eat', 'dest', 'vids'],\n",
    "          ['sleep', 'sleep', 'sleep', 'sleep'],\n",
    "          ['dest', 'sleep', 'dest', 'sleep', 'dest', 'eat']\n",
    "         ],\n",
    "         algorithm='baum-welch',\n",
    "         max_iterations=5,\n",
    "         distribution_inertia=0.3,\n",
    "         edge_inertia=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As more samples are added, the training improvement will be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.587726971074026"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm2.fit( [['eat', 'dest', 'sleep'], \n",
    "          ['dest', 'eat', 'sleep'],\n",
    "          ['eat', 'eat', 'eat', 'eat'],\n",
    "          ['dest', 'eat', 'sleep', 'sleep', 'sleep', 'eat']\n",
    "         ],\n",
    "         algorithm='baum-welch',\n",
    "         distribution_inertia=0.3,\n",
    "         edge_inertia=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting On the Trained Model\n",
    "Now that we have a model, we can make predictions with some new observed sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence: dest\teat\tdest\teat\tvids\tvids\tsleep\n",
      "hmm pred: 0\t1\t0\t1\t1\t1\t1\n",
      "\n",
      "sequence: dest\tvids\tdest\tvids\tdest\tvids\tdest\tsleep\tsleep\tsleep\n",
      "hmm pred: 0\t0\t0\t0\t0\t0\t0\t1\t1\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq3 = ['dest', 'eat', 'dest', 'eat', 'vids', 'vids', 'sleep']\n",
    "seq4 = ['dest', 'vids', 'dest', 'vids', 'dest', 'vids', 'dest', 'sleep', 'sleep', 'sleep']\n",
    "\n",
    "predictions_hmm2 = hmm.predict( seq3 )\n",
    "print(\"sequence: {}\".format( \"\\t\".join( seq3 )))\n",
    "print(\"hmm pred: {}\".format( \"\\t\".join( map( str, predictions_hmm2)) ), end=\"\\n\\n\")\n",
    "\n",
    "predictions_hmm2 = hmm.predict( seq4 )\n",
    "print(\"sequence: {}\".format( \"\\t\".join( seq4 )))\n",
    "print(\"hmm pred: {}\".format( \"\\t\".join( map( str, predictions_hmm2)) ), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What has our model learned?\n",
    "What do the transitions look like between the two models (hmm and hmm2)?\n",
    "\n",
    "How have they changed with training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmm1\n",
      " [[2.14863232 0.88474332 0.         0.        ]\n",
      " [0.63318129 2.33344306 0.         0.        ]\n",
      " [0.57970635 0.42029365 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]] \n",
      "\n",
      "hmm2\n",
      " [[3.40846775e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.31775465e-19 1.59153225e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 2.39045278e-45 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trans1, ems1 = hmm.forward_backward(seq3)\n",
    "print(\"hmm1\\n\",trans1,\"\\n\")\n",
    "\n",
    "trans2, ems2 = hmm2.forward_backward(seq3)\n",
    "print(\"hmm2\\n\",trans2,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Pomegranate is a nice package that has some great features for exploring sequential data.\n",
    "\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy_xbox.jpg?raw=true\" width=\"400px\" align=\"left\">\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy_Oatmeal.png?raw=true\" width=\"400px\" align=\"left\">\n",
    "<img src=\"https://github.com/mooneyj3/cs571_hmm_demos/blob/master/images/Chewy.jpg?raw=true\" width=\"250px\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
